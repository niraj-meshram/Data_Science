# Bagging and Boosting

Overview
- Ensemble learning techniques that combine many weak learners for stronger performance.
- Demonstrates bagging (e.g., Random Forest) and boosting (e.g., Gradient Boosting).

What It Does
- Trains ensembles on tabular datasets (heart/diabetes), compares against single trees, and reports metrics.

Run
- Open the notebook(s) and execute cells; adjust number of estimators and depth.

